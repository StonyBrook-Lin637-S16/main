\chapter{Notions of Generative Capacity}
\label{cha:GenCap}

Last time we saw that even though syntax does not define regular string languages due to center embedding (and possibly other constructions we have not considered yet), context-free grammars are powerful enough to handle center embedding.
And in an unexpected turn of events we quickly realized that context-free grammars can be viewed as a mechanism for generating strictly $2$-local tree languages.
So if this is on the right track, syntax does not look all that different from phonology: where a significant fragment of phonology is strictly local over strings, syntax may be strictly local over trees.
But as you remember, not all of phonology turned out to be strictly local, so we should not be too eager to claim that syntax is strictly local, either.
And as we will see today, this issue is a lot trickier to resolve for syntax.


\section{Weak and Strong Generative Capacity}
A strictly local tree grammar produces two distinct outputs --- a tree language and the corresponding string language.
These two notions are not in perfect alignment.
Failure to produce the right string language necessarily implies failure to produce the right tree language, but the opposite does not hold.
Moreover, a formalism that does not produce the right string language may still be closer to the correct tree language than one that gets the string language right but does so at the expense of ludicrous tree structures.
So if we assume that trees are indeed an integral part of syntax --- rather than just a convenient device for us to represent certain dependencies over strings --- then we have to make sure that strictly local grammars are sufficiently powerful to capture syntax at both the string level and the tree level.
In more technical terms, we have to ensure that they have adequate \emph{weak and strong generative capacity}.
%
\begin{description}
    \item[Weak Generative Capacity] the class of string languages that are generated by the formalism
    \item[Strong Generative Capacity] the class of tree languages that are generated by the formalism
\end{description}

Weak and strong generative capacity do not exhaust the full spectrum of levels of generative capacity.
One could also posit \emph{derivational capacity} as a metric for how succinctly a formalism produces a given tree, or \emph{relational capacity} as a metric for the string-meaning pairings that can be computed.
These notions are very little understood, though, so they play no big role at this point in the categorization of formalisms.
Even strong generative capacity is still severely understudied, though a lot of progress has been made in recent years.
This is partially due to theoretical computational linguistics undergoing a shift in interest from string languages to tree languages.
Another driving factor, however, is that more and more application areas build on tree languages.
XML, for example, is essentially a standard for dynamically specifying tree languages, which grants it an enormous amount of flexibility and makes it an ideal tool for APIs, among other things.
So this is yet another case where theoretical and applied interests converge, leading towards a new focus on understudied concepts --- in the case at hand, tree languages.

\section{Generative Capacity of Tree-Based Grammar Formalisms}

\subsection{Strictly Local Tree Grammars}

We already proved that $\SLT[k-1] \subsetneq \SLT[k]$ for all $k$, so the strong generative capacity of strictly local tree grammars increases with the size of their locality domain.
In addition, the tree languages generated by CFGs are a proper subclass of $\SLT[2]$ due to CFG's strict distinction between terminal and non-terminal nodes.
With respect to strong generative capacity, we thus obtain a strict hierarchy $\mathrm{CFG} \subsetneq \SLT[2] \subsetneq \SLT[3] \subsetneq \cdots$.
The strong generative capacity of CFGs and strictly $1$-local tree grammars is incomparable.
%
\Note{What does a CFG for the empty tree language look like? And what is the corresponding strictly $1$-local tree grammar?}
In fact, the two classes have only one tree language in common, and that is the empty language.
With the exception of these slightly deviant cases, though, we get a nice proper hierarchy that mirrors exactly the expressive hierarchy for strictly local string languages.

The fact that strong generative capacity increases with the size of the locality domain suggests that weak generative capacity does too.
After all, that's what we saw with strictly local string languages.
Surprisingly, though, this is not the case: weak generative capacity stays the same after $\SLT[2]$.
%
\begin{theorem}
    For all $k \geq 2$, $\Yield(\SLT[k])$ is the class of context-free languages.
\end{theorem}
%
We do not give a proof at this point since the theorem will fall out as a corollary of an even more general result later on.
Instead, let us look at some of the surprising repercussions of this fact.
A first important observation is that the string languages generated by strictly local tree grammars have very different closure properties compared to their tree languages.
%
\begin{lemma}
    The class of context-free languages is closed under union.
\end{lemma}
%
\begin{proof}
    It suffices to show that for any two CFGs $G_1 \is \tuple{\Sigma_1,S,R_1}$ and $G_2 \is \tuple{\Sigma_2,S,R_2}$ there is a CFG $G_3$ that generates $L(G_1) \cup L(G_2)$.
    One can construct $G_3$ in a manner that is similar to the union of automata:
    %
    \begin{itemize}
        \item for every rewrite rule $A \rewrite A_1 \cdots A_n$ in $R_i$ ($i \in \setof{1,2}$), $G_3$ contains the rewrite rule $A^i \rightarrow A_1^i \cdots A_1^i$,
        \item for every terminal symbol $a$ of $G_i$ ($i \in \setof{1,2}$), $G_3$ contains the rewrite rule $a^i \rewrite a$,
        \item the start symbol $S$ of $G_3$ only occurs in the rewrite rules $S \rightarrow S^1$ and $S \rightarrow S^2$.
    \end{itemize}
    %
    It is easy to see that $G_3$ generates every string that is a member of $L(G_1)$ or $L(G_2)$, and nothing else.
\end{proof}
%
\begin{examplebox}[Constructing the Union of Two CFGs]
    Suppose $m > n \geq 1$.
    Then $a^m b^n$ and $a^n b^m$ are both context-free languages generated by the respective set of rewrite rules below:
    %
    \begin{center}
        \begin{tabular}{rcl}
            $S$ & \rewrite & $aS$\\
            $S$ & \rewrite & $aT$\\
            $T$ & \rewrite & $aTb$\\
            $T$ & \rewrite & $ab$
        \end{tabular}
        %
        \hspace{2em}
        %
        \begin{tabular}{rcl}
            $S$ & \rewrite & $Sb$\\
            $S$ & \rewrite & $Tb$\\
            $T$ & \rewrite & $aTb$\\
            $T$ & \rewrite & $ab$
        \end{tabular}
    \end{center}
    %
    The trees for $\String{aaaabb}$ and $\String{aabbbb}$ are shown below.
    %
    \begin{center}
        \begin{forest}
            [S
                [a]
                [S
                    [a]
                    [T
                        [a]
                        [T
                            [a]
                            [b]
                        ]
                        [b]
                    ]
                ]
            ]
        \end{forest}
        %
        \hspace{2em}
        %
        \begin{forest}
            [S
                [S
                    [T
                        [a]
                        [T
                            [a]
                            [b]
                        ]
                        [b]
                    ]
                    [b]
                ]
                [b]
            ]
        \end{forest}
    \end{center}
    %
    The union of $a^m b^n$ and $a^n b^m$ is $a^+b^+ \setminus a^n b^n$.

    We now build a CFG $G_3$ for this language, meticulously following the steps in the proof.
    The first step collects all rewrite rules and adds a superscript to every symbol in the rule.
    %
    \begin{center}
        \begin{tabular}{rcl}
            $S^1$ & \rewrite & $a^1 S^1$\\
            $S^1$ & \rewrite & $a^1 T^1$\\
            $T^1$ & \rewrite & $a^1 T^1 b^1$\\
            $T^1$ & \rewrite & $a^1 b^1$
        \end{tabular}
        %
        \hspace{2em}
        %
        \begin{tabular}{rcl}
            $S^2$ & \rewrite & $S^2 b^2 $\\
            $S^2$ & \rewrite & $T^2 b^2 $\\
            $T^2$ & \rewrite & $a^2 T^2 b^2$\\
            $T^2$ & \rewrite & $a^2 b^2 $
        \end{tabular}
    \end{center}
    %
    Next we have to add a rewrite rule for every non-terminal that we superscripted.
    %
    \begin{center}
        \begin{tabular}{rcl}
            $a^1$ & \rewrite & a\\
            $a^2$ & \rewrite & a\\
            $b^1$ & \rewrite & b\\
            $b^2$ & \rewrite & b
        \end{tabular}
    \end{center}
    %
    Finally, we add the rules $S \rewrite S_1$ and $S \rewrite S_2$.
    After the initial rewrite step of $S$, this grammar behaves almost exactly like $G_1$ or $G_2$, depending on what $S$ was rewritten as.
    %
    \begin{center}
        \begin{forest}
            [S
                [S$^1$
                    [a$^1$ [a]]
                    [S$^1$
                        [a$^1$ [a]]
                        [T$^1$
                            [a$^1$ [a]]
                            [T$^1$
                                [a$^1$ [a]]
                                [b$^1$ [b]]
                            ]
                            [b$^1$ [b]]
                        ]
                    ]
                ]
            ]
        \end{forest}
        %
        \hspace{2em}
        %
        \begin{forest}
            [S
                [S$^2$
                    [S$^2$
                        [T$^2$
                            [a$^2$ [a]]
                            [T$^2$
                                [a$^2$ [a]]
                                [b$^2$ [b]]
                            ]
                            [b$^2$ [b]]
                        ]
                        [b$^2$ [b]]
                    ]
                    [b$^2$ [b]]
                ]
            ]
        \end{forest}
    \end{center}
\end{examplebox}

Closure under union is surprising, but even more so is non-closure under intersection.
%
\begin{lemma}
    The class of context-free languages is not closed under intersection.
\end{lemma}
%
\begin{proof}
    We are not in a position to fully prove this yet.
    The basic idea is as follows: $a^+ b^n c^n$ and $a^n b^n c^+$ are both context-free languages, but their intersection is $a^n b^n c^n$, which is not context-free.
    This can be shown via a pumping lemma, which we will encounter later on.
    %fixme: add reference to section
\end{proof}

How is it possible that the strictly local tree languages are closed under intersection but not union, while the very opposite holds for their string yields?
Shouldn't closure under intersection for tree languages imply closure under intersection for the string yields, too?
The answer is no, because the two intersection operations produce very different outputs.
Consider the tree languages $L_1$ and $L_2$ that only contain the trees [\tsb{S} [\tsb{A} a ]] and [\tsb{S} [\tsb{B} a ]], respectively.
Then $\Yield(L_1) = \Yield(L_2) = \setof{a}$, so the intersection of their string languages is also $\setof{a}$.
But if we directly intersect $L_1$ and $L_2$, we get the empty set instead because they have not a single tree in common.
And the string yield of the empty set is also the empty set, which definitely is not the same thing as $\setof{a}$.
So $\Yield(L_1) \cap \Yield(L_2) = \setof{a} \neq \emptyset = \Yield(L_1 \cap L_2)$.
It is this misalignment between intersecting tree languages and intersection their string yields that leads to the skewed closure property.

A similar problem arises with union.
Union of strictly local tree languages does not necessarily preserve their strict locality because we might be able to build completely new trees from the union of the $k$-trees.
But for union of the string yields, we can freely alter the tree structure, including relabeling interior nodes to keep the $k$-grams distinct.
So once again $\Yield(L_1) \cup \Yield(L_2)$ is not necessarily the same as $\Yield(L_1 \cup L_2)$, and closure under union for string languages cannot be lifted to the level of tree languages.

Keeping all of this mind, you should not be too surprised anymore that context-free languages are also closed under relabelings even though the strictly local tree languages are not.
%
\begin{lemma}
    The class of context-free languages is closed under relabelings.
\end{lemma}
%
\begin{proof}
    Suppose $L$ is generated by CFG $G \is \tuple{\Sigma,S,R} $ and the relabeling $\transduction$ is specified as a finite set of pairs $\tuple{a,b}$ such that $a \in \Sigma_T$.
    Then the image of $L$ under $\transduction$ is generated by the grammar $G'$ with $R' \is R \cup \setof{ a \rewrite b \mid \tuple{a,b} \in \transduction}$.
\end{proof}

\begin{theorem}
    The class of context-free languages is closed under union and relabelings.
    It is not closed under intersection and relative complement.
\end{theorem}

The difference in closure properties is both a strength and a weakness.
On the one hand, it makes things a lot trickier, and one always has to pay attention what kind of objects are being manipulated, tree languages or string languages.
On the other hand, it solves a problem we would be facing otherwise: if syntax defines context-free string languages, shouldn't we expect the union of two natural languages to be a natural language?
In our discussion of phonology we already pointed out that closure under union is not a property of natural languages because it allows constraints to apply disjunctively.
For syntax, the fact that some languages only enforce person agreement between the subject and the verb and some only number agreement would predict via closure under union that there is a language where the subject has to agree in person or number, but not both.
This seems unlikely, and it is readily accounted for if we take syntax to generate tree languages, where closure under union does not hold.
%fixme: find better example

\subsection{Refined Strictly Local Tree Grammars}

Now that we have a tree analogue for strictly local grammars, it makes sense to define an analogue for refined strictly local grammars and ask how their generative capacity compares to that of standard strictly local tree grammars.
%
\begin{definition}[Refined Tree Grammar]
    A \emph{refined strictly $k$-local tree grammar} $G$ is a finite set of $k$-trees over alphabet $\Sigma \times Q$.
    Such a grammar generates the tree language $L^T(G) \is \setof{ t \mid \exists r \in Q^{\augmented{t}}, \ktrees[k](r) \subseteq G }$.
    Its string language is $L^S(G) = \Yield(L^T(G))$.
    A tree language is refined strictly $k$-local (in $\SLTR$) iff it is generated by a refined strictly $k$-local tree grammar.
    The class of all refined strictly $k$-local tree languages is $\SLTR \is \bigcup_{k \geq 0} \SLTR[k]$.
\end{definition}
%
\begin{examplebox}[Two Refined Strictly $2$-Local Tree Languages]
    In lecture~\ref{cha:Trees}, we saw example of two tree languages that are not strictly local.
    The first one was the set of unary branching trees over alphabet $\setof{a}$ that contain an even number of nodes.
    This language is refined strictly $2$-local, though, as the construction for the string case can be lifted directly to unary branching trees.
    Let us look at a slight generalization instead, the set of all at most binary branching trees over alphabet $\setof{a}$ with an even number of nodes.
    This language contains the leftmost tree but not the other two.
    %
    \begin{center}
        \begin{forest}
            [a
                [a
                    [a]
                    [a]
                ]
                [a
                    [a]
                ]
            ]
        \end{forest}
        %
        \hspace{2em}
        %
        \begin{forest}
            [a
                [a
                    [a]
                    [a]
                ]
                [a]
            ]
        \end{forest}
        %
        \hspace{2em}
        %
        \begin{forest}
            [a
                [a
                    [a]
                    [a]
                ]
                [a
                    [a
                        [a]
                    ]
                ]
            ]
        \end{forest}
    \end{center}
    %
    In order to generate this tree language, one needs the refined $2$-trees below:
    %
    \begin{center}
        \begin{tabular}{cccc}
            \begin{forest}
                [\kState{o}{a}
                    [\kState{o}{\RightEdge}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{e}{a}
                    [\kState{o}{a}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{o}{a}
                    [\kState{e}{a}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{e}{\LeftEdge}
                    [\kState{e}{a}]
                ]
            \end{forest}
            \\
            \begin{forest}
                [\kState{o}{a}
                    [\kState{e}{a}]
                    [\kState{e}{a}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{e}{a}
                    [\kState{o}{a}]
                    [\kState{e}{a}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{e}{a}
                    [\kState{e}{a}]
                    [\kState{o}{a}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{e}{a}
                    [\kState{o}{a}]
                    [\kState{o}{a}]
                ]
            \end{forest}
        \end{tabular}
    \end{center}
    %
    The state assignments for the three trees above now show that only the leftmost is generated by the grammar.
    %
    \begin{center}
        \begin{forest}
            [\kState{e}{a}
                [\kState{e}{a}
                    [\kState{o}{a}]
                    [\kState{o}{a}]
                ]
                [\kState{e}{a}
                    [\kState{o}{a}]
                ]
            ]
        \end{forest}
        %
        \hspace{2em}
        %
        \begin{forest}
            [\kState{o}{a}
                [\kState{e}{a}
                    [\kState{o}{a}]
                    [\kState{o}{a}]
                ]
                [\kState{o}{a}
                ]
            ]
        \end{forest}
        %
        \hspace{2em}
        %
        \begin{forest}
            [\kState{o}{a}
                [\kState{e}{a}
                    [\kState{o}{a}]
                    [\kState{o}{a}]
                ]
                [\kState{o}{a}
                    [\kState{e}{a}
                        [\kState{o}{a}]
                    ]
                ]
            ]
        \end{forest}
    \end{center}

    The other language we looked at was $L_{b=1}$, the set of all strictly binary branching trees over $\setof{a,b}$ that contain exactly one instance of $b$.
    In this case, the states simply keep track of whether a $b$ has been seen yet.
    %
    \begin{center}
        \begin{tabular}{cccc}
            \begin{forest}
                [\kState{0}{a}
                    [\kState{0}{\RightEdge}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{b}
                    [\kState{1}{\RightEdge}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{\LeftEdge}
                    [\kState{1}{a}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{\LeftEdge}
                    [\kState{1}{b}]
                ]
            \end{forest}
            \\
            \begin{forest}
                [\kState{0}{a}
                    [\kState{0}{a}]
                    [\kState{0}{a}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{a}
                    [\kState{0}{a}]
                    [\kState{1}{a}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{a}
                    [\kState{1}{a}]
                    [\kState{0}{a}]
                ]
            \end{forest}
            \\
            \begin{forest}
                [\kState{1}{a}
                    [\kState{0}{a}]
                    [\kState{1}{b}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{a}
                    [\kState{1}{b}]
                    [\kState{0}{a}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{b}
                    [\kState{0}{a}]
                    [\kState{0}{a}]
                ]
            \end{forest}
        \end{tabular}
    \end{center}
    %
    The state assignment once again shows the distinction between well-formed and ill-formed trees.
    %
    \begin{center}
        \begin{forest}
            [\kState{1}{a}
                [\kState{0}{a}
                    [\kState{0}{a}
                        [\kState{0}{a}]
                        [\kState{0}{a}]
                    ]
                    [\kState{0}{a}]
                ]
                [\kState{1}{a}
                    [\kState{1}{a}
                        [\kState{0}{a}]
                        [\kState{1}{b}]
                    ]
                    [\kState{0}{a}]
                ]
            ]
        \end{forest}
        %
        \hspace{2em}
        %
        \begin{forest}
            [\kState{0}{a}
                [\kState{0}{a}
                    [\kState{0}{a}
                        [\kState{0}{a}]
                        [\kState{0}{a}]
                    ]
                    [\kState{0}{a}]
                ]
                [\kState{0}{a}
                    [\kState{0}{a}
                        [\kState{0}{a}]
                        [\kState{0}{a}]
                    ]
                    [\kState{0}{a}]
                ]
            ]
        \end{forest}
        %
        \hspace{2em}
        %
        \begin{forest}
            [\kState{}{a}
                [\kState{1}{a}
                    [\kState{1}{a}
                        [\kState{0}{a}]
                        [\kState{1}{b}]
                    ]
                    [\kState{0}{a}]
                ]
                [\kState{1}{a}
                    [\kState{1}{a}
                        [\kState{0}{a}]
                        [\kState{1}{b}]
                    ]
                    [\kState{0}{a}]
                ]
            ]
        \end{forest}
    \end{center}
\end{examplebox}

During our investigation of refined strictly local string languages, we saw that $\SL^R_k = \SL^R_{k+1}$ for all $k \geq 2$, which implies $\SL^R_2 = \SL^R$.
The equivalence holds because the extra information that is afforded by the increased locality domain can be encoded in the hidden alphabet layer.
For the very same reason, every strictly local language turns out to be refined strictly $2$-local.
Adapting the constructions used in the proof from strings to trees is straight-forward, and consequently we find the same relations among refined strictly local tree languages.
%
\begin{theorem}
    $\SLT \subsetneq \SLTR[2] = \SLTR$
\end{theorem}
%
These relations will allow us to prove rather elegantly that all $\SLT[k]$ have the same weak generative capacity.
For this is just a corollary of the fact that the class of context-free languages is exactly $\Yield(\SLTR[2])$.
%
\begin{theorem}[\citealt{Thatcher67}]
    CFGs are weakly equivalent to $\SLTR$.
\end{theorem}
%
\begin{proof}
    Since every CFG defines a strictly $2$-local tree language and $\SLT \subsetneq \SLTR[2]$, every context-free language is included in $\Yield(\SLTR[2])$.
    In the other direction, let $L \in \SLTR$.
    Then there is some refined strictly $2$-local tree grammar $G_2$ with $L^T(G_2) = L$.
    We construct a CFG $G_C$ such that $L^S(G_2) = L^S(G_C)$.

    Let $k \in G_2$.
    %
    \begin{itemize}
        \item If $k$ is of the form $[_{\kState{q}{\LeftEdge}} \kState{q_1}{A_1}]$, then $G_C$ contains the rewrite rule $S \rewrite \tuple{A_1,q_1}$.
        \item If $k$ is of the form $[_{\kState{q}{A}} \kState{q_1}{\RightEdge}]$, then $G_C$ contains the rewrite rule $\tuple{A,q} \rewrite A$.
        \item In all other cases, $k$ is of the form $[_{\kState{q}{A}} \kState{q_1}{A_1} \cdots \kState{q_n}{A_n}]$ ($n \leq 1$) and $G_C$ contains the rewrite rule $\tuple{A,q} \rewrite \tuple{A_1,q_1} \cdots \tuple{A_n,q_n}$.
    \end{itemize}

    Let $\transduction$ be the projection that maps every non-terminal symbol $\tuple{A,q}$ to $A$.
    Furthermore, $t[l \leftarrow l^2]$ is the tree that is obtained from $t$ by replacing every leaf $a$ with the tree $[_a a]$.
    Note that $\Yield(t) = \Yield(t[ \leftarrow l^2])$.
    Close inspection of the translation above reveals that $s \in L^T(G_2)$ iff there is a tree $t \in L^T(G_C)$ such that $\transduction(t) = [_S s[l \leftarrow l^2]]$.
    It follows that $\Yield(s) = \Yield(t)$, and by extension $L^S(G_2) = L^S(G_C)$. 
\end{proof}

\begin{examplebox}[Translating a Refined Tree Grammar Into a CFG]
    The previous example gave a refined strictly $2$-local grammar for $L_{b=1}$, the set of all strictly binary branching trees over $\setof{a,b}$ that contain exactly one instance of $b$.
    We consider a minor variant where only leafs can be labeled $b$.
    To this end we have to remove only one $2$-tree from the original grammar.
    %
    \begin{center}
        \begin{tabular}{ccccc}
            \begin{forest}
                [\kState{0}{a}
                    [\kState{0}{\RightEdge}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{b}
                    [\kState{1}{\RightEdge}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{\LeftEdge}
                    [\kState{1}{a}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{\LeftEdge}
                    [\kState{1}{b}]
                ]
            \end{forest}
            \\
            \begin{forest}
                [\kState{0}{a}
                    [\kState{0}{a}]
                    [\kState{0}{a}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{a}
                    [\kState{0}{a}]
                    [\kState{1}{a}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{a}
                    [\kState{1}{a}]
                    [\kState{0}{a}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{a}
                    [\kState{0}{a}]
                    [\kState{1}{b}]
                ]
            \end{forest}
            &
            \begin{forest}
                [\kState{1}{a}
                    [\kState{1}{b}]
                    [\kState{0}{a}]
                ]
            \end{forest}
        \end{tabular}
    \end{center}
    %
    The procedure described in the proof translates these nine $k$-grams into nine rewrite rules.
    %
    \begin{center}
        \begin{tabular}{rcl}
            $\tuple{a,0}$ & \rewrite & $a$\\
            $\tuple{b,1}$ & \rewrite & $b$\\
        \end{tabular}
        %
        \hspace{2em}
        %
        \begin{tabular}{rcl}
            $S$           & \rewrite & $\tuple{a,1}$\\
            $S$           & \rewrite & $\tuple{b,1}$
        \end{tabular}
        %
        \hspace{2em}
        %
        \begin{tabular}{rcl}
            $\tuple{a,0}$ & \rewrite & $\tuple{a,0}$ $\tuple{a,0}$\\
            $\tuple{a,1}$ & \rewrite & $\tuple{a,0}$ $\tuple{a,1}$\\
            $\tuple{a,1}$ & \rewrite & $\tuple{a,1}$ $\tuple{a,0}$\\
            $\tuple{a,1}$ & \rewrite & $\tuple{a,0}$ $\tuple{b,1}$\\
            $\tuple{a,1}$ & \rewrite & $\tuple{b,1}$ $\tuple{a,0}$
        \end{tabular}
    \end{center}
    %
    The well-formed tree from the previous example now has the left tree as its correspondent, while the right tree shows the image under $\transduction$.
    %
    \begin{center}
        \begin{forest}
            [S
                [\tuple{a,1}
                    [\tuple{a,0}
                        [\tuple{a,0}
                            [\tuple{a,0}
                                [a]
                            ]
                            [\tuple{a,0}
                                [a]
                            ]
                        ]
                        [\tuple{a,0}
                            [a]
                        ]
                    ]
                    [\tuple{a,1}
                        [\tuple{a,1}
                            [\tuple{a,0}
                                [a]
                            ]
                            [\tuple{b,1}
                                [b]
                            ]
                        ]
                        [\tuple{a,0}
                            [a]
                        ]
                    ]
                ]
            ]
        \end{forest}
        %
        \hspace{2em}
        %
        \begin{forest}
            [S
                [a
                    [a
                        [a
                            [a
                                [a]
                            ]
                            [a
                                [a]
                            ]
                        ]
                        [a]
                    ]
                    [a
                        [a
                            [a
                                [a]
                            ]
                            [b
                                [b]
                            ]
                        ]
                        [a]
                    ]
                ]
            ]
        \end{forest}
    \end{center}
\end{examplebox}

We now have a very intriguing result: CFGs, strictly local tree grammars, and refined strictly local tree grammars all have the same weak generative capacity.
The choice between them thus cannot be motivated by well-formedness data since the well-formedness of a sentence in, say, English only tells us that it belongs to the string language defined by English, and all these formalisms define exactly the same string languages.
If we want to make an informed choice between these formalisms, it will have to be in terms of the tree languages they can define.
That is a much more subtle issue that requires a lot of linguistic finesse.
But more on that next time.
